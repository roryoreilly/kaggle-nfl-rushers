{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4331e937-6f14-449c-b415-0ca4e6164d4b",
    "_uuid": "aa5d49a6-d080-4d3e-ac19-892474eb44c0"
   },
   "source": [
    "# NFL Big Data Bowl 2019 EDA\n",
    " \n",
    " This will be my beginning EDA to expore the data.\n",
    " This is my basic eploritory before looking at other EDA's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "91c146e2-d92b-4ebb-af89-6166c46572b7",
    "_uuid": "30b34cb5-26a4-436d-b64b-a4cdba8984c9"
   },
   "source": [
    "## Setup\n",
    " Imports and getting the data into a dataframe. Basic exploritory of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e512e9d2-694e-49a8-88c1-0ef9c8dd75d6",
    "_uuid": "884454eb-a0c7-4aa7-9547-4b43b1d821f3"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import datetime\n",
    "# from kaggle.competitions import nflrush\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU, Input, PReLU, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "141736dd-aa25-4162-b12a-601f9bd0e26a",
    "_uuid": "20e87e91-db91-4c43-9b41-8a37941e2341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kaggle/competitions/nflrush/sample_submission.csv.encrypted\n",
      "./kaggle/competitions/nflrush/__init__.py\n",
      "./kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n",
      "./kaggle/competitions/nflrush/test.csv.encrypted\n",
      "./kaggle/competitions/nflrush/__pycache__/__init__.cpython-37.pyc\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0d1ef019-0759-485c-bd18-66ff6dcc0e15",
    "_uuid": "60e10c79-b18c-491c-a3fd-81dd4bc97383"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a612387-914a-454b-8c40-b757debc3798",
    "_uuid": "c6c1ecba-137a-45fd-8bfd-06858cff0b88"
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00a08250-ca8b-4703-850d-0c61f986ff3e",
    "_uuid": "1ce588a0-ba9c-491b-bccb-fddd497c5cb6"
   },
   "outputs": [],
   "source": [
    "avg_dis= train_df.query('NflIdRusher == NflId').groupby('DisplayName')[['Dis','DisplayName']].mean()\n",
    "avg_dis.sort_values(by=['Dis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b3810d9-427d-4216-9a26-268e90a8a46d",
    "_uuid": "8ea39070-62be-4300-85fc-4ba2adb6c428"
   },
   "outputs": [],
   "source": [
    "train_df['GameId'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b0e445cc-48bc-4c4d-90c5-37de49e134ef",
    "_uuid": "366109a6-c457-46f2-8322-8bc42929df7d"
   },
   "source": [
    "## Displaying of players\n",
    " Using the code from this notebook. It is a simple solution to displaying the players. \n",
    " And the time spent making it can be put to better use\n",
    " https://www.kaggle.com/robikscube/nfl-big-data-bowl-plotting-player-position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a9c1ff0-b76e-42e4-b8d1-57274d692eb4",
    "_uuid": "3415b53a-1ab2-4006-89dd-d979e5310680"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n",
    "\n",
    "def create_football_field(linenumbers=True,\n",
    "                          endzones=True,\n",
    "                          highlight_line=False,\n",
    "                          highlight_line_number=50,\n",
    "                          highlighted_name='Line of Scrimmage',\n",
    "                          fifty_is_los=False,\n",
    "                          figsize=(12, 6.33)):\n",
    "    \"\"\"\n",
    "    Function that plots the football field for viewing plays.\n",
    "    Allows for showing or hiding endzones.\n",
    "    \"\"\"\n",
    "    rect = patches.Rectangle((0, 0), 120, 53.3, linewidth=0.1,\n",
    "                             edgecolor='r', facecolor='darkgreen', zorder=0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.plot([10, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n",
    "              80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n",
    "             [0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3,\n",
    "              53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n",
    "             color='white')\n",
    "    if fifty_is_los:\n",
    "        plt.plot([60, 60], [0, 53.3], color='gold')\n",
    "        plt.text(62, 50, '<- Player Yardline at Snap', color='gold')\n",
    "    # Endzones\n",
    "    if endzones:\n",
    "        ez1 = patches.Rectangle((0, 0), 10, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ez2 = patches.Rectangle((110, 0), 120, 53.3,\n",
    "                                linewidth=0.1,\n",
    "                                edgecolor='r',\n",
    "                                facecolor='blue',\n",
    "                                alpha=0.2,\n",
    "                                zorder=0)\n",
    "        ax.add_patch(ez1)\n",
    "        ax.add_patch(ez2)\n",
    "    plt.xlim(0, 120)\n",
    "    plt.ylim(-5, 58.3)\n",
    "    plt.axis('off')\n",
    "    if linenumbers:\n",
    "        for x in range(20, 110, 10):\n",
    "            numb = x\n",
    "            if x > 50:\n",
    "                numb = 120 - x\n",
    "            plt.text(x, 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white')\n",
    "            plt.text(x - 0.95, 53.3 - 5, str(numb - 10),\n",
    "                     horizontalalignment='center',\n",
    "                     fontsize=20,  # fontname='Arial',\n",
    "                     color='white', rotation=180)\n",
    "    if endzones:\n",
    "        hash_range = range(11, 110)\n",
    "    else:\n",
    "        hash_range = range(1, 120)\n",
    "\n",
    "    for x in hash_range:\n",
    "        ax.plot([x, x], [0.4, 0.7], color='white')\n",
    "        ax.plot([x, x], [53.0, 52.5], color='white')\n",
    "        ax.plot([x, x], [22.91, 23.57], color='white')\n",
    "        ax.plot([x, x], [29.73, 30.39], color='white')\n",
    "\n",
    "    if highlight_line:\n",
    "        hl = highlight_line_number + 10\n",
    "        plt.plot([hl, hl], [0, 53.3], color='yellow')\n",
    "        plt.text(hl + 2, 50, '<- {}'.format(highlighted_name),\n",
    "                 color='yellow')\n",
    "    return fig, ax\n",
    "\n",
    "def plot_runner(runner_df, ax):\n",
    "    x = runner_df['X'].values[0]\n",
    "    y = runner_df['Y'].values[0]\n",
    "    rad = math.radians(runner_df['Dir'].values[0])\n",
    "    dx = math.cos(rad) * 5\n",
    "    dy = math.sin(rad) * 5\n",
    "    print(runner_df['Dir'].values[0])\n",
    "    ax.plot(x=x, y=y, kind='scatter', color='red', s=30, legend='Runner')\n",
    "    ax.arrow(x=x, y=y, dx=dx, dy=dy, head_width=1)\n",
    "\n",
    "def display_play(playid):\n",
    "    yl = train.query(\"PlayId == @playid\")['YardLine'].tolist()[1]\n",
    "    fig, ax = create_football_field(highlight_line=True,\n",
    "                                    highlight_line_number=yl+54)\n",
    "    plot_runner(train.query(\"PlayId == @playid and NflIdRusher == NflId\"), ax)\n",
    "    train.query(\"PlayId == @playid and Team == 'away'\") \\\n",
    "        .plot(x='X', y='Y', kind='scatter', ax=ax, color='orange', s=30, legend='Away')\n",
    "    train.query(\"PlayId == @playid and Team == 'home' and NflIdRusher != NflId\") \\\n",
    "        .plot(x='X', y='Y', kind='scatter', ax=ax, color='blue', s=30, legend='Home')\n",
    "    plt.title(f'Play # {playid}')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "playid = 20181230154157\n",
    "display_play(playid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dfbb0aa8-d20c-4e35-b27f-94c594cce0e8",
    "_uuid": "5411fc93-4da3-4d4e-85d9-ec0764ff5ec4"
   },
   "outputs": [],
   "source": [
    "game_df = train_df.query('GameId == 2018123015')\n",
    "i = 0\n",
    "total_plays = 0\n",
    "for playid in game_df.PlayId.unique():\n",
    "    display_play(playid)\n",
    "    i += 1\n",
    "    if i > total_plays:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "55c5663b-4f51-4a8c-977c-50b2a3048d3e",
    "_uuid": "5cd1e2f2-8701-4834-80aa-34232285c111"
   },
   "source": [
    "## Submission data\n",
    " I'll go through the test data and example submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae51a7b0-75a0-477d-931f-54f862c247dd",
    "_uuid": "b6c279f7-afee-4543-ac9d-0b07499f023e"
   },
   "outputs": [],
   "source": [
    "submit = False\n",
    "if submit:\n",
    "    env = nflrush.make_env()\n",
    "\n",
    "    for (test_df, sample_prediction_df) in env.iter_test():\n",
    "        env.predict(sample_prediction_df)\n",
    "    env.write_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ae57aef-67f2-4b1d-bea3-4c2541256eab",
    "_uuid": "f811c47b-0af7-42ea-8e46-36665d83ac11"
   },
   "source": [
    "# Normalise the data\n",
    "## Same direction\n",
    " First step is to have the attacking always from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f15bf19-faf5-4e11-84b1-bf1a85460138",
    "_uuid": "0ae14f02-d11d-4fae-a850-9e08446b778c"
   },
   "outputs": [],
   "source": [
    "def correct_team_abbr(df_input):\n",
    "    df = df_input.copy()\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "    for abb in train['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n",
    "    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n",
    "    df['VisitorTeamAbbr'] =df['VisitorTeamAbbr'].map(map_abbr)\n",
    "    return df\n",
    "\n",
    "def correct_direction(df):\n",
    "    std_df = df.copy()\n",
    "    plays_incor_dir = train_df.query(\"NflIdRusher == NflId  and PlayDirection == 'left'\")['PlayId'].values\n",
    "    home_has_the_ball = train_df.query(\"NflIdRusher == NflId and Team == 'home'\")['PlayId'].values\n",
    "    away_has_the_ball = train_df.query(\"NflIdRusher == NflId and Team == 'away'\")['PlayId'].values\n",
    "    std_df['X_Std'] = np.where(std_df['PlayId'].isin(plays_incor_dir), 120-std_df['X'], std_df['X'])\n",
    "    std_df['Y_Std'] = np.where(std_df['PlayId'].isin(plays_incor_dir), 53.3-std_df['Y'], std_df['Y'])\n",
    "    std_df['YardLine_Std'] = np.where(std_df['PlayId'].isin(plays_incor_dir), 100-std_df['YardLine'], std_df['YardLine'])\n",
    "    std_df['Orientation_Std'] = np.where(std_df['PlayId'].isin(plays_incor_dir), (std_df['Orientation']+180) % 360, std_df['Orientation'])\n",
    "    std_df['Dir_Std'] = np.where(std_df['PlayId'].isin(plays_incor_dir), (std_df['Dir']+180) % 360, std_df['Dir'])\n",
    "    std_df['HasBall'] = np.where(np.logical_or(np.logical_and(std_df['PlayId'].isin(home_has_the_ball), std_df['Team'] == 'home'), np.logical_and(std_df['PlayId'].isin(away_has_the_ball), std_df['Team'] == 'away')), True, False)\n",
    "    std_df['IsRusher'] = np.where(std_df['NflIdRusher'] == std_df['NflId'], True, False)\n",
    "    return std_df\n",
    "\n",
    "def fix_data(df_input):\n",
    "    df = correct_team_abbr(df_input)\n",
    "    df = correct_direction(df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def handle_na(df):\n",
    "    return df.dropna()\n",
    "\n",
    "# std_df = correct_direction(train_df)\n",
    "# std_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "41a155ca-d176-418c-8145-d42a50365c1d",
    "_uuid": "b8c5237f-5333-4098-9559-07adc3110120"
   },
   "source": [
    "## Column Fixing\n",
    " Columns can be replaced with other values that will allow the deep learning algorithm to work correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e39291ee-911c-4bb6-bb16-90d3fc555395",
    "_uuid": "9322a97e-139b-4863-b703-f4a698316f60"
   },
   "outputs": [],
   "source": [
    "def strtoseconds(txt):\n",
    "    txt = txt.split(':')\n",
    "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "    return ans\n",
    "\n",
    "def normalise_windspeed(input_df):\n",
    "    df = input_df.copy()\n",
    "    df['WindSpeed'] = input_df.query(\"WindSpeed in ('E', 'SE', 'SSW')\")['WindDirection']\n",
    "    df['WindDirection'] = input_df.query(\"WindSpeed in ('E', 'SE', 'SSW')\")['WindSpeed']\n",
    "    df['WindSpeed'] = df[\"WindSpeed\"].apply(lambda x: 0 if x == 'Calm' else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    df['WindSpeed'] = df['WindSpeed'].astype(float)\n",
    "    return df\n",
    "    \n",
    "def normalise_weather(input_df):\n",
    "    return input_df.drop(['GameWeather'], axis=1)\n",
    "    \n",
    "def normalise_columns(input_df):\n",
    "    df = input_df.copy()\n",
    "    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "    df['GameClock'] = df['GameClock'].apply(strtoseconds)\n",
    "    df = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\n",
    "    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/31557600.0, axis=1)\n",
    "    df = df.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n",
    "    df['Team'] = df['Team'].apply(lambda x: x.strip()=='home')\n",
    "    df = normalise_windspeed(df)\n",
    "    df = normalise_weather(df)\n",
    "    return df\n",
    "\n",
    "# std_df = normalise_columns(std_df)\n",
    "# std_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8932b7b9-2d34-468e-82c6-d04fd3f8ee16",
    "_uuid": "4750bdbf-25f0-4936-ab12-05b432d01755"
   },
   "source": [
    "## Rusher related stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "96c6bcb5-a5ea-4a9e-990e-dad1ae0477e3",
    "_uuid": "0e289cae-8b2f-44fb-9e04-a5ff3e97c12f"
   },
   "outputs": [],
   "source": [
    "def add_defensive_stats(train_df_input, df_input):\n",
    "    df = df_input.copy()\n",
    "    train_df = train_df_input.copy()\n",
    "    train_df['DefensiveTeam'] = np.where(train_df['PossessionTeam'] == train_df['HomeTeamAbbr'], train_df['VisitorTeamAbbr'], train_df['HomeTeamAbbr'])\n",
    "    mean_dict = train_df.query('IsRusher == True').groupby('DefensiveTeam')['Yards'].mean().to_dict()\n",
    "    df['DefensiveYardsAgainst'] = train_df['DefensiveTeam'].map(mean_dict)\n",
    "    return df\n",
    "    \n",
    "def add_season_mean(train_df,df_input):\n",
    "    df = df_input.copy()\n",
    "    mean_dict = train_df.query(\"IsRusher == True\").groupby(['Season','DisplayName'])['Yards'].mean()\n",
    "    for year in range(2017, 2020):\n",
    "        try:\n",
    "            df[\"RusherMeanYards_{}\".format(year)] = df['DisplayName'].map(mean_dict[year])\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "def add_rusher_stats(train_df,df_input):\n",
    "    df = df_input.copy()\n",
    "    mean_dict = train_df.query('IsRusher == True').groupby('DisplayName')['Yards'].mean().to_dict()\n",
    "    df['RusherMeanYards'] = df['DisplayName'].map(mean_dict)\n",
    "    return df\n",
    "\n",
    "def add_yards_stats(train_df,df_input):\n",
    "    df = df_input.copy()\n",
    "    df = add_rusher_stats(train_df,df)\n",
    "    df = add_season_mean(train_df,df)\n",
    "    df = add_defensive_stats(train_df,df)\n",
    "    df = df.fillna(-1)\n",
    "    return df\n",
    "    \n",
    "#add_yards_stats(std_df_nor, std_df_nor.iloc[0:22]).query('IsRusher == True').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f89456a-9c41-42e1-a1f6-3fa15cb9215e",
    "_uuid": "a1e84235-0044-4b9f-93a6-fcc180d0aeca"
   },
   "source": [
    "## Closest Defense\n",
    " Getting the closest defensive player to the runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c105916-cec7-4c62-8fc8-3c2f38512067",
    "_uuid": "36b983dd-1756-47ff-bc9d-ba04d536c724"
   },
   "outputs": [],
   "source": [
    "def add_closest_defensive_player(df):\n",
    "    playids = df.query(\"NflIdRusher == NflId\")['PlayId'].values\n",
    "    df['ClosestDefense'] = -1.0\n",
    "    for playid in playids:\n",
    "        runner = df.query(\"PlayId == @playid and IsRusher == True\")\n",
    "        defense = df.query(\"PlayId == @playid and HasBall == False\")\n",
    "        d_pos = defense[['X_Std', 'Y_Std']].values\n",
    "        r_pos = runner[['X_Std', 'Y_Std']].values\n",
    "        min_dis = distance.cdist(r_pos,d_pos).min(axis=1)\n",
    "        df.at[runner.index.values.astype(int)[0], 'ClosestDefense'] = min_dis\n",
    "    return df\n",
    "\n",
    "#Want to get closest player in FoV\n",
    "def add_closest_fov_player(df):\n",
    "    playids = df.query(\"NflIdRusher == NflId\")['PlayId'].values\n",
    "    df['ClosestDefense'] = -1.0\n",
    "    df['ClosestDefenseFov'] = -1.0\n",
    "    for playid in playids:\n",
    "        runner = df.query(\"PlayId == @playid and IsRusher == True\")\n",
    "        defense = df.query(\"PlayId == @playid and HasBall == False\")\n",
    "    \n",
    "        d_pos = defense[['X_Std', 'Y_Std']].values\n",
    "        r_pos = runner[['X_Std', 'Y_Std']].values\n",
    "        min_dis = distance.cdist(r_pos,d_pos).min(axis=1)\n",
    "        df.at[runner.index.values.astype(int)[0], 'ClosestDefense'] = min_dis\n",
    "        \n",
    "        if ((runner['Orientation_Std'] >= 45) | (runner['Orientation_Std'] <= 135)).values[0]:\n",
    "            y_max = runner['Y_Std'].values[0]-3\n",
    "            defense = defense[defense['Y_Std']>y_max]\n",
    "        elif ((runner['Orientation_Std'] >= 225) | (runner['Orientation_Std'] <= 305)).values[0]:\n",
    "            y_max = runner['Y_Std'].values[0]+3\n",
    "            defense = defense[defense['Y_Std']<y_max]\n",
    "        d_pos = defense[['X_Std', 'Y_Std']].values\n",
    "        r_pos = runner[['X_Std', 'Y_Std']].values\n",
    "        try:\n",
    "            min_dis = distance.cdist(r_pos,d_pos).min(axis=1)\n",
    "        except ValueError:\n",
    "            min_dis = -1\n",
    "        df.at[runner.index.values.astype(int)[0], 'ClosestDefenseFov'] = min_dis\n",
    "    return df\n",
    "\n",
    "def closest_player_stats(df_input):\n",
    "    df = df_input.copy()\n",
    "    df = add_closest_fov_player(df)\n",
    "    #df = add_closest_defensive_player(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0a6c4e41-288c-4649-98c0-0f4ef083136f",
    "_uuid": "3fe55625-4495-4cf4-8beb-42028917fe86"
   },
   "source": [
    "## Flatten Data\n",
    " Get all players data into a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90338533-ef37-4d9b-b205-f77605b8ab9a",
    "_uuid": "226ec9ab-89a3-47fb-b58a-4676c47e0902"
   },
   "outputs": [],
   "source": [
    "# Remove some columns at the moment\n",
    "def remove_columns(df):\n",
    "    cat_features = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype =='object':\n",
    "            cat_features.append(col)\n",
    "    df = df.drop(cat_features, axis=1)\n",
    "    return df\n",
    "\n",
    "def flatten(df_input):\n",
    "    df = df_input.copy()\n",
    "    df = df.sort_values(by=['PlayId', 'HasBall', 'IsRusher']).reset_index()\n",
    "    player_columns = ['JerseyNumber','PlayerHeight','PlayerWeight','PlayerAge','X_Std','Y_Std','Orientation_Std','Dir_Std','S','A']\n",
    "    drop_columns = ['X','Y','Dis','Orientation','HasBall','IsRusher', 'Team','NflId','DisplayName','PlayerCollegeName','FieldPosition','StadiumType']\n",
    "    \n",
    "    player_np = np.array(df[player_columns].fillna(df[player_columns].mean())).reshape(-1, 10*22)\n",
    "    play_df = df.drop(columns=player_columns, axis=1).query('IsRusher == True').drop(drop_columns, axis=1)\n",
    "    play_df = remove_columns(play_df)\n",
    "    play_df = play_df.fillna(play_df.mean())\n",
    "    \n",
    "    play_np = np.array(play_df)\n",
    "    X = np.concatenate((play_np, player_np), axis=1)\n",
    "    return play_np\n",
    "\n",
    "#flatten(std_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a003210b-6637-488c-8e29-15f47c48e579",
    "_uuid": "73f09f5e-0f63-48c5-94bf-5fde98b90389"
   },
   "source": [
    "# Saving dataframe and reloading it\n",
    " My dataframe is slow to build. Let's save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0bf6e54-3204-454c-a460-44f8665dfb1e",
    "_uuid": "ba56bdbf-f936-4e65-a9ed-e2b1773c4749"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    std_df = pd.read_pickle(\"/kaggle/input/nflrunnerdataframe/std_df.pkl\")\n",
    "    print('Created Dataframe')\n",
    "except FileNotFoundError:\n",
    "    print('Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b44fb292-0a73-463d-ad1f-a5f41ba4c7c6",
    "_uuid": "2d67d6ef-3a76-4004-9ced-d4f4f36e311c"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    std_df\n",
    "except (AttributeError, NameError):\n",
    "    std_df_c_d = fix_data(train_df)\n",
    "    std_df_nor = normalise_columns(std_df_c_d)\n",
    "    std_with_yards = add_yards_stats(std_df_nor, std_df_nor)\n",
    "    std_df = closest_player_stats(std_with_yards)\n",
    "    std_df.to_pickle(\"std_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd4be1df-3276-4d6c-a067-82b6e050f7ae",
    "_uuid": "7ac66da0-6a99-4ec8-bdc4-ec2fac4a6f69"
   },
   "source": [
    "# Making a model\n",
    " Given our data how would we go about making a small model to make the prediction\n",
    " \n",
    " Y values should be organised of 0.0 for yards it got past. \n",
    " And 1.0 for yards it reached. An example of a player that reached 2 yards\n",
    "     \n",
    "     yards  -99  -98  -97  -96  ....  -1  0  1  2  3  4  .... 97  98  99\n",
    "     result   0    0    0    0         0  0  0  1  1  1        1   1   1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6e0b2036-8790-4608-8ff1-3d715a0e1886",
    "_uuid": "d0cf049a-7239-4f37-a637-c49d1de68bc2"
   },
   "outputs": [],
   "source": [
    "# Flatten data and get single one yards amount per row\n",
    "Y_set = std_df.query('NflIdRusher == NflId')['Yards']\n",
    "X_set = flatten(std_df)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train_yards, y_test_yards = train_test_split(X_set, Y_set, test_size=0.1, random_state=1)\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "\n",
    "Y_train=np.zeros((X_train.shape[0],199))\n",
    "for i,yard in enumerate(y_train_yards):\n",
    "    Y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n",
    "\n",
    "Y_test=np.zeros((X_test.shape[0],199))\n",
    "for i,yard in enumerate(y_test_yards):#\n",
    "    Y_test[i, yard+99:] = np.ones(shape=(1, 100-yard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fcc74004-fda6-44bb-a3b8-ee8015fc3e7e",
    "_uuid": "3105d009-3de5-46d4-9d4f-69835b62b343"
   },
   "outputs": [],
   "source": [
    "def crps(y_true,y_pred):\n",
    "    diffs = (y_true - y_pred) ** 2\n",
    "    sum_tf = tf.math.reduce_sum(tf.math.reduce_sum(diffs, axis=1), axis=0)\n",
    "    return sum_tf / (199 * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20b198c1-ec30-4df7-bc45-d3904ef61ea9",
    "_uuid": "e38d47e8-b8c4-41b6-8224-7927872d37f9"
   },
   "outputs": [],
   "source": [
    "# class OuputLayer(layers.Layer):\n",
    "\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(OuputLayer, self).__init__(**kwargs)\n",
    "    \n",
    "#     def get_output_shape_for(self, input_shape):\n",
    "#         return (input_shape[0], self.n_mels, input_shape[2])\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "#         yardline = tf.Variable(inputs[0][0]).read_value()\n",
    "#         print(yardline)\n",
    "#         dense_output = inputs[1]\n",
    "#         zeros = tf.Variable(tf.zeros(shape=(199,),dtype = tf.float32))\n",
    "#         ones = tf.Variable(tf.ones(shape=(199,),dtype = tf.float32))\n",
    "# #         tf.assign(dense_output[0:99-yardline], zeros[0:99-yardline])\n",
    "# #         tf.assign(dense_output[99+yardline:-1], ones[99+yardline:-1])\n",
    "#         return dense_output\n",
    "\n",
    "def create_model(input_size):\n",
    "    inputs = Input(input_size)\n",
    "#     yardline_input = Input(1)\n",
    "    x = Dense(input_size, activation='relu')(inputs)\n",
    "    x = Dense(input_size, activation='relu')(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dense(512, activation=None)(x)\n",
    "#     x = PReLU()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = Dense(512, activation=None)(x)\n",
    "#     x = PReLU()(x)\n",
    "#     shortcut = x\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = Dense(512, activation=None)(x)\n",
    "#     x = PReLU()(x)\n",
    "#     x = Add()([x, shortcut])\n",
    "#     x = Dropout(0.5)(x)\n",
    "    x = Dense(199, activation='sigmoid')(x)\n",
    "#     classifier = OuputLayer()([yardline_input,x])\n",
    "#     model = Model(inputs=[inputs,yardline_input], outputs=[classifier])\n",
    "    model = Model(inputs=[inputs], outputs=[x])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00005), loss=['mse'], metrics=[crps])\n",
    "    return model\n",
    "model = create_model(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aba78fac-d3a7-4a80-8545-5f6964d31186",
    "_uuid": "17fcdca1-2f41-492d-bfb9-7454a830f8fa"
   },
   "outputs": [],
   "source": [
    "# def create_model(input_shape):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(256, input_shape=[input_shape], activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(LeakyReLU(0.3))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(LeakyReLU(0.3))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.4))\n",
    "#     model.add(Dense(199, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.00005), loss=['mse'], metrics=[crps])\n",
    "#     return model\n",
    "# model = create_model(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5be17b15-23d7-4305-b102-2a43e1ab9760",
    "_uuid": "9781ad10-d329-46d0-9424-f4d7ae03aa87"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"model.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "history = model.fit(X_train, \n",
    "                  Y_train, \n",
    "                  epochs=10,\n",
    "                  batch_size=32,\n",
    "#                   callbacks=[cp_callback],  \n",
    "                  validation_data=(X_test, Y_test))\n",
    "\n",
    "# model.load_weights(\"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cf3ea187-8fca-4540-b7be-c85c14bd8939",
    "_uuid": "fdf74fa6-2a2d-4a30-ac33-9c6b5d04674e"
   },
   "outputs": [],
   "source": [
    "def make_pred(df, model, train_df, env=None, sample=None):\n",
    "    test_df = fix_data(df)\n",
    "    test_df = normalise_columns(test_df)\n",
    "    test_df = add_yards_stats(train_df, test_df)\n",
    "    test_df = closest_player_stats(test_df)\n",
    "    \n",
    "    dummy_col = train_df.columns\n",
    "    missing_cols = set( dummy_col ) - set( test_df.columns )-set('Yards')\n",
    "    for c in missing_cols:\n",
    "        test_df[c] = 0\n",
    "    test_df = test_df.drop('Yards',axis=1)\n",
    "    x_pred = flatten(test_df)\n",
    "    x_pred = scaler.transform(x_pred)\n",
    "    y_pred = np.zeros((1,199))\n",
    "    y_pred = model.predict(x_pred)\n",
    "    for pred in y_pred:\n",
    "        pred[0:99-test_df['YardLine_Std'].values[0]] = 0.0\n",
    "        pred[199-test_df['YardLine_Std'].values[0]:-1] = 1.0\n",
    "        prev = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i]<prev:\n",
    "                pred[i]=prev\n",
    "            prev=pred[i]\n",
    "    if (env):\n",
    "        env.predict(pd.DataFrame(data=y_pred,columns=sample.columns))\n",
    "    return y_pred\n",
    "    \n",
    "for i in range(0,5):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    a = make_pred(train_df.iloc[i*22:22+(i*22)], model, std_df)\n",
    "    # a = make_pred(stupid[0], model, std_df)\n",
    "    plt.plot(np.arange(-99,100), a[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "bb5a5ea5-41de-454f-bd31-b25bb81c28ca",
    "_uuid": "14039bf4-0afe-4f9f-9536-c07ffd804706"
   },
   "outputs": [],
   "source": [
    "stupid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "4083058e-3500-4288-b6f6-e44711006fec",
    "_uuid": "ce1a2324-250c-4955-ab48-840b9ed79b48"
   },
   "outputs": [],
   "source": [
    "env = nflrush.make_env()\n",
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    try:\n",
    "        make_pred(test_df, model, std_df, env=env, sample=sample_prediction_df)\n",
    "    except ValueError:\n",
    "        stupid.append(test_df)\n",
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
