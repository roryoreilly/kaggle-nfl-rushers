{"cells":[{"metadata":{"_uuid":"28672645-5a46-4e97-b820-10dbe8182513","_cell_guid":"ee6e60e5-80cc-4591-8144-279603de4b4a","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport timeit\nimport pandas as pd\nimport numpy as np\nimport math\nimport tensorflow as tf\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Dropout, PReLU\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import KFold\nfrom kaggle.competitions import nflrush\nimport lightgbm as lgb\npd.set_option('max_columns', 200)\npd.set_option('max_rows', 100)\npd.set_option('display.width', 1000)\nnp.set_printoptions(linewidth=1000)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PersistentFeatures:\n\n    def __init__(self, nfl_df):\n        self.nfl = nfl_df\n        self.rushers = self.nfl.loc[self.nfl.NflId == self.nfl.NflIdRusher]\n        self.rushers.set_index('PlayId', inplace=True)\n        self.rusher_features = pd.DataFrame(self.rushers['NflId'].unique(), columns=['NflId'])\n        self.columns = []\n        self.scaler = StandardScaler()\n\n    def build_features(self):\n        self._rusher_features()\n\n    def attach_columns(self, columns):\n        self.columns = columns\n\n    def _rusher_features(self):\n        self._rusher_mean_yards()\n\n    def _rusher_mean_yards(self):\n        mean_dict = self.rushers.groupby(['Season', 'NflId'])['Yards'].mean()\n        for year in range(2017, 2020):\n            try:\n                self.rusher_features[\"RusherMeanYards_{}\".format(year)] = self.rusher_features['NflId'].map(mean_dict[year])\n            except IndexError:\n                pass\n        mean_dict = self.rushers.groupby('NflId')['Yards'].mean().to_dict()\n        self.rusher_features['RusherMeanYards'] = self.rusher_features['NflId'].map(mean_dict)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeatureExtractor:\n    def __init__(self, nfl_df, persistent_features, is_test=False, model_type='nn'):\n        self.nfl = nfl_df\n        self.is_test = is_test\n        self.persistent_features = persistent_features\n        self.model_type = model_type\n        self._normalise_starting_df()\n        self.rushers = self.nfl.loc[self.nfl.IsRusher]\n        self.features = self.rushers[['PlayId', 'GameId', 'NflId']]\n        self.rushers.set_index('PlayId', inplace=True)\n        self.features.set_index('PlayId', inplace=True)\n        self.results = np.zeros((self.features.shape[0], 199))\n\n    def run(self):\n        self.attach_persistent_features()\n        self.rusher_features()\n        self.game_features()\n        self.defense_features()\n        self.offense_features()\n        self.play_features()\n        self.features = self.features.fillna(self.features.mean())\n\n        if self.is_test:\n            full_columns = self.persistent_features.columns\n            missing_cols = set(full_columns) - set(self.features.columns)\n            for c in missing_cols:\n                self.features[c] = 0\n        else:\n            self._make_result_set()\n            self.persistent_features.scaler.fit(self.features)\n\n    def get_final_features(self):\n        return self.persistent_features.scaler.transform(self.features)\n\n    def attach_persistent_features(self):\n        self.features.reset_index().merge(self.persistent_features.rusher_features, on='NflId').set_index('PlayId')\n\n    def _make_result_set(self):\n        if self.model_type == 'lgbm':\n            self.results = np.zeros((self.features.shape[0])) #, 199))\n        \n        for i, yard in enumerate(self.rushers.Yards):\n            if self.model_type == 'lgbm':\n                self.results[i] = yard\n            else:\n                self.results[i, yard + 99:] = np.ones(shape=(1, 100 - yard))\n\n    def play_features(self):\n        self.features['DistanceToQB'] = np.sqrt(np.sum(\n            self.nfl.loc[(self.nfl.Position == 'QB') | self.nfl.IsRusher, ['PlayId', 'X_std', 'Y_std']].groupby(\n                'PlayId').agg(['min', 'max']).diff(axis=1).drop([('X_std', 'min'), ('Y_std', 'min')], axis=1) ** 2,\n            axis=1))\n\n    def defense_features(self):\n        self.features['Def_DL'] = np.array(self.rushers['DefensePersonnel'].str[:1], dtype='int8')\n        self.features['Def_LB'] = np.array(self.rushers['DefensePersonnel'].str[6:7], dtype='int8')\n        self.features['Def_DB'] = np.array(self.rushers['DefensePersonnel'].str[12:13], dtype='int8')\n        self._defenders_in_the_box()\n\n    def _defenders_in_the_box(self):\n        self.features['DefendersInTheBox'] = self.rushers['DefendersInTheBox']\n        self.features['DITB_Centroid_X'] = \\\n            self.nfl.loc[self.nfl.IsDefenderInBox].groupby('PlayId')[['X_std']].mean()\n        self.features['DITB_Centroid_Y'] = \\\n            self.nfl.loc[self.nfl.IsDefenderInBox].groupby('PlayId')[['Y_std']].mean()\n        self.features['DITB_Spread_X'] = \\\n            self.nfl.loc[self.nfl.IsDefenderInBox].groupby('PlayId')['X_std'].agg(['min', 'max']).diff(axis=1)['max']\n        self.features['DITB_Spread_Y'] = \\\n            self.nfl.loc[self.nfl.IsDefenderInBox].groupby('PlayId')['Y_std'].agg(['min', 'max']).diff(axis=1)['max']\n\n    def offense_features(self):\n        self.features['Off_RB'] = np.array(self.rushers['OffensePersonnel'].str.extract('(\\d) RB'), dtype='int8')\n        self.features['Off_TE'] = np.array(self.rushers['OffensePersonnel'].str.extract('(\\d) TE'), dtype='int8')\n        self.features['Off_WR'] = np.array(self.rushers['OffensePersonnel'].str.extract('(\\d) WR'), dtype='int8')\n        off_formations = [pd.get_dummies(self.rushers['OffenseFormation'], prefix='Off_Formation')]\n        self.features = self.features.join(off_formations)\n\n    def game_features(self):\n        self.features['Week'] = self.rushers['Week']\n        self.features['Season_2017'] = self.features['Season_2018'] = self.features['Season_2019'] = 0\n        self.features.loc[self.rushers.Season == 2017, 'Season_2017'] = 1\n        self.features.loc[self.rushers.Season == 2018, 'Season_2018'] = 1\n        self.features.loc[self.rushers.Season == 2019, 'Season_2019'] = 1\n\n        self.features['Quarter'] = self.rushers['Quarter']\n        self.features['GameClock_std'] = (900.0 - self.rushers['GameClock'].apply(stringtomins)) / 900.0\n        self.features['FullGameClock_std'] = (self.features['GameClock_std'] / 4.0) + (\n                (self.features['Quarter'] - 1) * 0.25)\n\n        self.features['OffenseScoreDelta'] = self.rushers['HomeScoreBeforePlay'] - self.rushers[\n            'VisitorScoreBeforePlay']\n        self.features.loc[self.rushers.PossessionTeam != self.rushers.HomeTeamAbbr, 'OffenseScoreDelta'] \\\n            = -1 * self.features.loc[self.rushers.PossessionTeam != self.rushers.HomeTeamAbbr, 'OffenseScoreDelta']\n\n        self.features['YardLine_std'] = self.rushers['YardLine_std']\n        self.features['Down'] = self.rushers['Down']\n        self.features['IsFirstAndTen'] = 1\n        self.features.loc[(self.rushers.Distance != 10.0) | (self.rushers.Down != 1), 'IsFirstAndTen'] = 0\n\n    def rusher_features(self):\n        rushers_features = self.rushers[['S', 'A', 'Dis', 'Orientation', 'Dir', 'PlayerHeight',\n                                         'PlayerWeight', 'X_std', 'Y_std', 'Dir_rad', 'Dir_std', 'S_std']].copy(deep=True)\n        rushers_features['PlayerHeight'] = rushers_features['PlayerHeight'] \\\n            .apply(lambda x: 12 * int(x.split('-')[0]) + int(x.split('-')[1]))\n\n        self.features = self.features.join(rushers_features)\n        self._rusher_position_ohe()\n\n    def _rusher_position_ohe(self):\n        rusher_position = [pd.get_dummies(self.rushers['Position'], prefix='Rusher_Position')]\n        self.features = self.features.join(rusher_position)\n\n    def _normalise_starting_df(self):\n        self._fix_team_abbr()\n        self._fix_orientation()\n        self._fix_speed()\n        self._add_possession_columns()\n        self._flip_left_plays()\n        self._distance_to_centers()\n\n    def _fix_team_abbr(self):\n        map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n        for abb in self.nfl['PossessionTeam'].unique():\n            map_abbr[abb] = abb\n        self.nfl['PossessionTeam'] = self.nfl['PossessionTeam'].map(map_abbr)\n        self.nfl['HomeTeamAbbr'] = self.nfl['HomeTeamAbbr'].map(map_abbr)\n        self.nfl['VisitorTeamAbbr'] = self.nfl['VisitorTeamAbbr'].map(map_abbr)\n\n    def _fix_orientation(self):\n        self.nfl.loc[self.nfl['Season'] == 2017, 'Orientation'] \\\n            = np.mod(90 + self.nfl.loc[self.nfl['Season'] == 2017, 'Orientation'], 360)\n\n    def _fix_speed(self):\n        self.nfl['S_std'] = self.nfl['S']\n        self.nfl.loc[self.nfl['Season'] == 2017, 'S'] \\\n            = (self.nfl['S'][self.nfl['Season'] == 2017] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n\n    def _flip_left_plays(self):\n        self.nfl['ToLeft'] = self.nfl.PlayDirection == \"left\"\n        self.nfl['YardLine_std'] = 100 - self.nfl.YardLine\n        self.nfl.loc[self.nfl.FieldPosition.fillna('') == self.nfl.PossessionTeam, 'YardLine_std'] \\\n            = self.nfl.loc[self.nfl.FieldPosition.fillna('') == self.nfl.PossessionTeam, 'YardLine']\n\n        self.nfl['X_std'] = self.nfl.X\n        self.nfl.loc[self.nfl.ToLeft, 'X_std'] = 120 - self.nfl.loc[self.nfl.ToLeft, 'X']\n        self.nfl['Y_std'] = self.nfl.Y - 160 / 6\n        self.nfl.loc[self.nfl.ToLeft, 'Y_std'] = 160 / 6 - self.nfl.loc[self.nfl.ToLeft, 'Y']\n\n        self.nfl['Dir_rad'] = np.mod(90 - self.nfl.Dir, 360) * math.pi / 180.0\n        self.nfl['Dir_std'] = self.nfl.Dir_rad\n        self.nfl.loc[self.nfl.ToLeft, 'Dir_std'] = np.mod(np.pi + self.nfl.loc[self.nfl.ToLeft, 'Dir_rad'], 2 * np.pi)\n\n    def _add_possession_columns(self):\n        self.nfl['IsRusher'] = self.nfl.NflId == self.nfl.NflIdRusher\n        self.nfl['TeamOnOffense'] = \"home\"\n        self.nfl.loc[self.nfl.PossessionTeam != self.nfl.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n        self.nfl['IsOnOffense'] = self.nfl.Team == self.nfl.TeamOnOffense\n\n    def _distance_to_centers(self):\n        self.nfl['DisFromPlayStart'] = np.sqrt(\n            (self.nfl.X_std - self.nfl.YardLine_std - 10) ** 2 + (self.nfl.Y_std ** 2))\n        ranks = self.nfl.groupby(['PlayId', 'IsOnOffense'])['DisFromPlayStart'] \\\n            .rank(ascending=True, method='first')\n        ranks.name = 'RankDisFromPlayStart'\n        self.nfl = pd.concat([self.nfl, ranks], axis=1)\n        self.nfl['IsDefenderInBox'] = False\n        self.nfl.loc[(~self.nfl.IsOnOffense) &\n                     (self.nfl.DefendersInTheBox >= self.nfl.RankDisFromPlayStart), ['IsDefenderInBox']] = True\n\n\ndef stringtomins(x):\n    h, m, s = map(int, x.split(':'))\n    return (h * 60) + m + (s / 60)\n","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model:\n    def __init__(self, input_shape, type='nn', batch_size=32, epochs=13, feature_columns=None):\n        self.type = type\n        self.input_shape = input_shape\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.feature_importance_df = pd.DataFrame()\n        self.feature_columns = feature_columns\n        self.fold = 0\n\n    def next(self, x_train, y_train, x_test, y_test):\n        if self.type == 'nn':\n            model = self._create_nn(x_train, y_train, x_test, y_test)\n        elif self.type == 'lgbm':\n            model = self._create_lgbm(x_train, y_train, x_test, y_test)\n        self.fold += 1\n        return model\n\n    def _create_nn(self, x_train, y_train, x_test, y_test):\n        model = Sequential()\n        model.add(Dense(256, input_shape=[self.input_shape], activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(256, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(199, activation='sigmoid'))\n\n        model.compile(optimizer='adam', loss=['mse'])\n        \n        earlystop_callback = EarlyStopping(monitor='mse', min_delta=0.0001, patience=3)\n        model.fit(x_train,\n                  y_train,\n#                       callbacks=[earlystop_callback],\n                  epochs=self.epochs,\n                  verbose=1,\n                  validation_data=(x_test, y_test))\n        return model\n\n    def _create_lgbm(self, x_train, y_train, x_test, y_test):\n        best_params_lgb = {'lambda_l1': 0.13413394854686794,\n                               'lambda_l2': 0.0009122197743451751,\n                               'num_leaves': 44,\n                               'feature_fraction': 0.4271070738920401,\n                               'bagging_fraction': 0.9999128827046064,\n                               'bagging_freq': 3,\n                               'learning_rate': 0.005,\n                               'min_child_samples': 43,\n                               'objective': 'regression',\n                               'metric': 'mae',\n                               'verbosity': -1,\n                               'boosting_type': 'gbdt',\n                               \"boost_from_average\": False,\n                               'random_state': 42}\n        model = lgb.LGBMRegressor(**best_params_lgb, \n                                  n_estimators = 300, \n                                  n_jobs = -1)\n        model.fit(x_train,\n                  y_train,\n                  eval_set=[(x_test, y_test)],\n                  early_stopping_rounds=self.epochs,\n                  eval_metric='mae',\n                  verbose=False)\n        self._lgbm_feature_importance(model)\n        return model\n    \n    def _lgbm_feature_importance(self, model):\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"Feature\"] = self.feature_columns\n        fold_importance_df[\"importance\"] = model.feature_importances_[:len(self.feature_columns)]\n        fold_importance_df[\"fold\"] = self.fold\n        self.feature_importance_df = pd.concat([self.feature_importance_df, fold_importance_df], axis=0)\n\n    def eval_feature_importance(self):\n        print(\"Features importance...\")\n        cols_imp = (self.feature_importance_df[[\"Feature\", \"importance\"]]\n                    .groupby(\"Feature\")\n                    .mean()\n                    .sort_values(by=\"importance\", ascending=False)[:50].index)\n        best_features = self.feature_importance_df.loc[self.feature_importance_df.Feature.isin(cols_imp)]\n\n        plt.figure(figsize=(14, 26))\n        sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n        plt.title('LightGBM Features (averaged over folds)')\n        plt.tight_layout()\n        plt.show()\n","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model_generator, fe, k_fold_splits=5):\n    print(\"Training model for {} folds\".format(5))\n    models = []\n\n    games_df = fe.features.reset_index()['GameId']\n    games = np.unique(games_df.values)\n\n    x = fe.get_final_features()\n    y = fe.results\n    kf = KFold(n_splits=k_fold_splits)\n    kf.get_n_splits(games)\n    for game_train_index, game_test_index in kf.split(games):\n        train_index = games_df.loc[games_df.isin(games[game_train_index])].index.tolist()\n        test_index = games_df.loc[games_df.isin(games[game_test_index])].index.tolist()\n        x_train, x_test = x[train_index], x[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model = model_generator.next(x_train, y_train, x_test, y_test)\n        models.append(model)\n    return models\n","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(test_features, models, yardline):\n    pred = np.zeros((1, 199))\n    for model in models:\n        _pred = model.predict(test_features)\n        pred += _pred\n\n    pred /= len(models)\n    prev = 0\n    for i in range(len(pred[0])):\n        if pred[0][i]<prev:\n            pred[0][i-1]=pred[0][i]\n            pred[0][i]=prev\n        if pred[0][i] > 1.0:\n            pred[0][i] = 1.0\n        prev=pred[0][i]\n    # Clip predictions past the yardline, as a player cannot go further than endzone\n#     pred[0][0:99 - yardline] = 0.0\n#     pred[0][100 + yardline:-1] = 1.0\n    return pred","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class App:\n    def __init__(self, model_type='nn'):\n        self.models = []\n        self.model_type = model_type\n\n    def run(self, make_submission=False):\n        train_df = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n        train_df = train_df.loc[train_df.Season != '2017']\n\n        pf = PersistentFeatures(train_df)\n        self._timer(pf.build_features, \"Persistent features\")\n        \n        fe = FeatureExtractor(train_df, pf, model_type=self.model_type)\n        self._timer(fe.run, \"Training features\")\n\n        pf.attach_columns(fe.features.columns)\n\n        features = fe.get_final_features()\n        m = Model(features.shape[1], epochs=10, type=self.model_type, feature_columns=fe.features.columns)\n        self.models = train(m, fe)\n        if self.model_type == 'lgbm':\n            m.eval_feature_importance()\n        if make_submission:\n            self.predict_on_env(pf)\n    \n    def _timer(self, function, description):\n        t0 = timeit.default_timer()\n        function()\n        t1 = timeit.default_timer()\n        print('Finished on {}. It took {}s'.format(description, t1 - t0))\n\n    def predict_on_env(self, pf):\n        env = nflrush.make_env()\n        i = 0\n        preds = None\n        t0 = timeit.default_timer()\n        for (test_df, sample) in env.iter_test():\n            fe = FeatureExtractor(test_df, pf, is_test=True)\n            fe.run()\n            pred = predict(fe.get_final_features(), self.models, fe.features['YardLine_std'].values[0])\n            pred_df = pd.DataFrame(data=pred, columns=sample.columns)\n            env.predict(pred_df)\n#             if preds is not None:\n#                 preds = pd.concat([preds, pred_df], sort=False)\n#             else:\n#                 preds = pred_df\n                \n            i += 1\n            if i % 100 == 0:\n                t1 = timeit.default_timer()\n                print(\"Processed {} plays. {} to go. Current elapsed time is {} seconds\".format(i, 3438-i, t1-t0))\n        env.write_submission_file()\n#         return preds\n","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app = App(model_type='nn')\napp.run()\napp.run(make_submission=True)","execution_count":null,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = method(y)\n","name":"stderr"},{"output_type":"stream","text":"Finished on Persistent features. It took 0.01178058200457599s\nFinished on Training features. It took 1.96995665000577s\nTraining model for 5 folds\nTrain on 18368 samples, validate on 4803 samples\n18368/18368 [==============================] - 3s 174us/sample - loss: 0.0195 - val_loss: 0.0133\nTrain on 18407 samples, validate on 4764 samples\n18407/18407 [==============================] - 3s 159us/sample - loss: 0.0193 - val_loss: 0.0131\nTrain on 18602 samples, validate on 4569 samples\n18602/18602 [==============================] - 3s 150us/sample - loss: 0.0199 - val_loss: 0.0127\nTrain on 18694 samples, validate on 4477 samples\n18694/18694 [==============================] - 3s 158us/sample - loss: 0.0193 - val_loss: 0.0147\nTrain on 18613 samples, validate on 4558 samples\n18613/18613 [==============================] - 3s 147us/sample - loss: 0.0188 - val_loss: 0.0147\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = method(y)\n","name":"stderr"},{"output_type":"stream","text":"Finished on Persistent features. It took 0.015076288997079246s\nFinished on Training features. It took 1.4535197960067308s\nTraining model for 5 folds\nTrain on 18368 samples, validate on 4803 samples\n18368/18368 [==============================] - 2s 136us/sample - loss: 0.0194 - val_loss: 0.0133\nTrain on 18407 samples, validate on 4764 samples\n18407/18407 [==============================] - 3s 148us/sample - loss: 0.0196 - val_loss: 0.0131\nTrain on 18602 samples, validate on 4569 samples\n18602/18602 [==============================] - 3s 149us/sample - loss: 0.0194 - val_loss: 0.0127\nTrain on 18694 samples, validate on 4477 samples\n18694/18694 [==============================] - 3s 147us/sample - loss: 0.0189 - val_loss: 0.0147\nTrain on 18613 samples, validate on 4558 samples\n18613/18613 [==============================] - 3s 147us/sample - loss: 0.0193 - val_loss: 0.0147\nProcessed 100 plays. 3338 to go. Current elapsed time is 42.56859615200665 seconds\nProcessed 200 plays. 3238 to go. Current elapsed time is 83.24097229300241 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}